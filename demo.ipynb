{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bosco\\documents\\test\\embedding\\venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bosco\\Documents\\test\\embedding\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-multiset-base')\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-multiset-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-multiset-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-multiset-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-multiset-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-reader-multiset-base were not used when initializing DPRReader: ['span_predictor.encoder.bert_model.pooler.dense.bias', 'span_predictor.encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRReader from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRReader from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRReaderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRReader, DPRReaderTokenizer\n",
    "reader = DPRReader.from_pretrained('facebook/dpr-reader-multiset-base')\n",
    "reader_tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-multiset-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'snowwhite.txt', 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    text = ''\n",
    "    for line in lines:\n",
    "        if len(line.strip()) > 0:\n",
    "            text += ' ' + line.strip()\n",
    "    sentences = list(map(lambda x: x.strip(), text.split('.')))\n",
    "    \n",
    "contexts = []\n",
    "for i in range(0, len(sentences)-3):\n",
    "    context = '.'.join(sentences[i:i+3])\n",
    "    contexts.append(context)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ctx_encoder and ctx_tokenizer are already loaded\n",
    "inputs = ctx_tokenizer(contexts, return_tensors=\"pt\", truncation=True, max_length=256, padding='max_length')\n",
    "passage_embeddings = ctx_encoder(**inputs).pooler_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([143, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What did the wicked Queen ask the Magic Mirror?\",\n",
    "    \"What did the Queen ordered the Huntsman to do to the Snow White?\",\n",
    "    \"Where did she go after the Huntsman left her deep into the forest?\",\n",
    "    \"What did she do when she entered the cottage?\",\n",
    "    \"What happened to the Snow White after she ate the poisoned apple?\",\n",
    "    \"What did the Dwarfs do when they found Snow White lying on the ground?\",\n",
    "    \"Who came to rescue Snow White?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_inputs = question_tokenizer(questions, return_tensors=\"pt\", truncation=True, max_length=256, padding='max_length')\n",
    "question_embedding = question_encoder(**question_inputs).pooler_output\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer(question, contexts):\n",
    "\n",
    "    reader_inputs = reader_tokenizer(\n",
    "        question, \n",
    "        contexts, \n",
    "        return_tensors=\"pt\", \n",
    "    )\n",
    "\n",
    "    reader_output = reader(**reader_inputs)\n",
    "    start_logits, end_logits = reader_output.start_logits, reader_output.end_logits\n",
    "\n",
    "    # Find the tokens with the highest `start` and `end` logits\n",
    "    answer_start = torch.argmax(start_logits)\n",
    "    answer_end = torch.argmax(end_logits) + 1  # Add 1 to get inclusive range\n",
    "\n",
    "    # Convert tokens to answer\n",
    "    answer_tokens = reader_inputs.input_ids[0, answer_start:answer_end]\n",
    "    answer = reader_tokenizer.decode(answer_tokens)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contexts(question_embedding, passage_embeddings, contexts, k=3):\n",
    "    probs = cos_sim(question_embedding, passage_embeddings)\n",
    "    # topk = torch.topk(probs, k=k)\n",
    "    # indices = topk.indices.tolist()[0]\n",
    "    # return ' \\n'.join([contexts[i] for i in indices])\n",
    "    index = torch.argmax(probs)\n",
    "    return contexts[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched contexts: The glass answered, oh, queen, of all here the fairest art thou, but the young queen is fairer by far as I trow.Then the wicked woman uttered a curse, and was so wretched, so utterly wretched that she knew not what to do.At first she would not go to the wedding at all, but she had no peace, and had to go to see the young queen\n",
      "What did the wicked Queen ask the Magic Mirror?\n",
      "ans: wicked woman uttered a curse\n",
      "---\n",
      "matched contexts: She called a huntsman, and said, take the child away into the forest.I will no longer have her in my sight.Kill her, and bring me back her lung and liver as a token\n",
      "What did the Queen ordered the Huntsman to do to the Snow White?\n",
      "ans: take the child away into the forest. i will no longer have her in my sight. kill\n",
      "---\n",
      "matched contexts: And envy and pride grew higher and higher in her heart like a weed, so that she had no peace day or night.She called a huntsman, and said, take the child away into the forest.I will no longer have her in my sight\n",
      "Where did she go after the Huntsman left her deep into the forest?\n",
      "ans: into the forest\n",
      "---\n",
      "matched contexts: When they saw snow-white lying as if dead upon the ground they at once suspected the step-mother, and they looked and found the poisoned comb.Scarcely had they taken it out when snow-white came to herself, and told them what had happened.Then they warned her once more to be upon her guard and to open the door to no one\n",
      "What did she do when she entered the cottage?\n",
      "ans: snow - white\n",
      "---\n",
      "matched contexts: Are you afraid of poison, said the old woman, look, I will cut the apple in two pieces, you eat the red cheek, and I will eat the white.The apple was so cunningly made that only the red cheek was poisoned.Snow-white longed for the fine apple, and when she saw that the woman ate part of it she could resist no longer, and stretched out her hand and took the poisonous half\n",
      "What happened to the Snow White after she ate the poisoned apple?\n",
      "ans: red cheek\n",
      "---\n",
      "matched contexts: The dwarfs, when they came home in the evening, found snow-white lying upon the ground, she breathed no longer and was dead.They lifted her up, looked to see whether they could find anything poisonous, unlaced her, combed her hair, washed her with water and wine, but it was all of no use, the poor child was dead, and remained dead.They laid her upon a bier, and all seven of them sat round it and wept for her, and wept three days long\n",
      "What did the Dwarfs do when they found Snow White lying on the ground?\n",
      "ans: \n",
      "---\n",
      "matched contexts: Then she told them that her step-mother had wished to have her killed, but that the huntsman had spared her life, and that she had run for the whole day, until at last she had found their dwelling.The dwarfs said, if you will take care of our house, cook, make the beds, wash, sew and knit, and if you will keep everything neat and clean you can stay with us and you shall want for nothing.Yes, said snow-white, with all my heart\n",
      "Who came to rescue Snow White?\n",
      "ans: the huntsman\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, xq_vec in enumerate(question_embedding):\n",
    "    matched_contexts = find_contexts(xq_vec, passage_embeddings, contexts)\n",
    "    print('matched contexts:', matched_contexts)\n",
    "    answer = find_answer(questions[i], matched_contexts)\n",
    "    print(questions[i])\n",
    "    print('ans:', answer)\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
